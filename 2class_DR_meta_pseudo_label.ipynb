{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67caa755",
   "metadata": {},
   "source": [
    "### Setup Environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3572f44e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff7164ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from src.get_dataset import get_dataset, split_data\n",
    "from src.data_loader import BRSETDataset, process_labels\n",
    "from src.model import FoundationalCVModel, FoundationalCVModelWithClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "# ResNet-50 모델 불러오기\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "\n",
    "# 모델 구조 출력\n",
    "print(resnet50)\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "# loss function and optimizer\n",
    "from src.FocalLoss import BinaryFocalLoss, FocalLoss\n",
    "\n",
    "# train and test functions\n",
    "from src.train import train\n",
    "from src.test import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41c1eda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Constants:\n",
    "DATASET = 'data'\n",
    "DOWNLOAD = False\n",
    "SHAPE = (224, 224)\n",
    "LABEL = 'DR_ICDR'\n",
    "TEST_SIZE = 0.3\n",
    "UNDERSAMPLE = False\n",
    "\n",
    "LABELS_PATH = os.path.join(DATASET, 'labels.csv')\n",
    "IMAGE_COL = 'image_id'\n",
    "\n",
    "\"\"\"\n",
    "Dataset Mean and Std:\n",
    "NORM_MEAN = [0.5896205017400412, 0.29888971649817453, 0.1107679405196557]\n",
    "NORM_STD = [0.28544273712830986, 0.15905456049750208, 0.07012281660980953]\n",
    "\n",
    "ImageNet Mean and Std:\n",
    "NORM_MEAN = [0.485, 0.456, 0.406]\n",
    "NORM_STD = [0.229, 0.224, 0.225]\n",
    "\"\"\"\n",
    "\n",
    "NORM_MEAN = None # [0.485, 0.456, 0.406]\n",
    "NORM_STD = None # [0.229, 0.224, 0.225]\n",
    "\n",
    "BACKBONE = 'resnet50'\n",
    "MODE = 'fine_tune'\n",
    "backbone_mode = 'fine_tune'\n",
    "\n",
    "HIDDEN = [128]\n",
    "num_classes = 2\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "LOSS = None #'focal_loss'\n",
    "OPTIMIZER = 'adam'\n",
    "\n",
    "# Define your hyperparameters\n",
    "num_epochs = 50\n",
    "learning_rate = 1e-5\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device  = torch.device(\"mps\")\n",
    "    IMAGES = os.path.join('a-brazilian-multilabel-ophthalmological-dataset-brset-1.0.0/fundus_photos')\n",
    "\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    IMAGES = os.path.join(r'data\\fundus_photos')\n",
    "\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986a7eab",
   "metadata": {},
   "source": [
    "#### Read csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0487e2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading csv file in data/labels.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>camera</th>\n",
       "      <th>patient_age</th>\n",
       "      <th>comorbidities</th>\n",
       "      <th>diabetes_time_y</th>\n",
       "      <th>insuline</th>\n",
       "      <th>patient_sex</th>\n",
       "      <th>exam_eye</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>...</th>\n",
       "      <th>vascular_occlusion</th>\n",
       "      <th>hypertensive_retinopathy</th>\n",
       "      <th>drusens</th>\n",
       "      <th>hemorrhage</th>\n",
       "      <th>retinal_detachment</th>\n",
       "      <th>myopic_fundus</th>\n",
       "      <th>increased_cup_disc</th>\n",
       "      <th>other</th>\n",
       "      <th>quality</th>\n",
       "      <th>normality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img00001</td>\n",
       "      <td>1</td>\n",
       "      <td>Canon CR</td>\n",
       "      <td>48.0</td>\n",
       "      <td>diabetes1</td>\n",
       "      <td>12</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img00002</td>\n",
       "      <td>1</td>\n",
       "      <td>Canon CR</td>\n",
       "      <td>48.0</td>\n",
       "      <td>diabetes1</td>\n",
       "      <td>12</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img00003</td>\n",
       "      <td>2</td>\n",
       "      <td>Canon CR</td>\n",
       "      <td>18.0</td>\n",
       "      <td>diabetes1</td>\n",
       "      <td>7</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img00004</td>\n",
       "      <td>2</td>\n",
       "      <td>Canon CR</td>\n",
       "      <td>18.0</td>\n",
       "      <td>diabetes1</td>\n",
       "      <td>7</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img00005</td>\n",
       "      <td>3</td>\n",
       "      <td>Canon CR</td>\n",
       "      <td>22.0</td>\n",
       "      <td>diabetes1</td>\n",
       "      <td>11</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  patient_id    camera  patient_age comorbidities diabetes_time_y  \\\n",
       "0  img00001           1  Canon CR         48.0     diabetes1              12   \n",
       "1  img00002           1  Canon CR         48.0     diabetes1              12   \n",
       "2  img00003           2  Canon CR         18.0     diabetes1               7   \n",
       "3  img00004           2  Canon CR         18.0     diabetes1               7   \n",
       "4  img00005           3  Canon CR         22.0     diabetes1              11   \n",
       "\n",
       "  insuline  patient_sex  exam_eye diabetes  ... vascular_occlusion  \\\n",
       "0      yes            1         1      yes  ...                  0   \n",
       "1      yes            1         2      yes  ...                  0   \n",
       "2      yes            2         1      yes  ...                  0   \n",
       "3      yes            2         2      yes  ...                  0   \n",
       "4      yes            1         1      yes  ...                  0   \n",
       "\n",
       "  hypertensive_retinopathy  drusens  hemorrhage  retinal_detachment  \\\n",
       "0                        0        0           0                   0   \n",
       "1                        0        0           0                   0   \n",
       "2                        0        0           0                   0   \n",
       "3                        0        0           0                   0   \n",
       "4                        0        0           0                   0   \n",
       "\n",
       "   myopic_fundus  increased_cup_disc  other   quality  normality  \n",
       "0              0                   1      0  Adequate   abnormal  \n",
       "1              0                   1      0  Adequate   abnormal  \n",
       "2              0                   0      0  Adequate     normal  \n",
       "3              0                   0      0  Adequate     normal  \n",
       "4              0                   0      0  Adequate     normal  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_dataset(DATASET, download=DOWNLOAD, info=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c6b0fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15210\n",
      "DR_ICDR\n",
      "Normal                  1056\n",
      "Diabetic Retinopathy    1056\n",
      "Name: count, dtype: int64\n",
      "15212\n",
      "1054\n",
      "15210\n",
      "1056\n"
     ]
    }
   ],
   "source": [
    "# Convert into 2 classes:\n",
    "\n",
    "# Normal = 0; Non-proliferative = 1, 2, 3; Proliferative = 4\n",
    "# Map values to categories\n",
    "df[LABEL] = df[LABEL].apply(lambda x: 'Normal' if x == 0 else 'Diabetic Retinopathy')\n",
    "\n",
    "normal_df = df[df['DR_ICDR'] == 'Normal']\n",
    "\n",
    "print(len(normal_df))\n",
    "diabetic_df = df[df['DR_ICDR'] == 'Diabetic Retinopathy']\n",
    "\n",
    "# 'Normal' 데이터에서 무작위로 1056개 샘플을 선택\n",
    "normal_downsampled = normal_df.sample(n=1056, random_state=42)  # random_state는 결과의 재현성을 위함\n",
    "\n",
    "# 다운샘플링된 'Normal' 데이터와 모든 'Diabetic Retinopathy' 데이터를 합치기\n",
    "balanced_df = pd.concat([normal_downsampled, diabetic_df])\n",
    "\n",
    "# 결과 확인\n",
    "print(balanced_df['DR_ICDR'].value_counts())\n",
    "\n",
    "\n",
    "print(len(df[df['DR_SDRG']==0]))\n",
    "print(len(df[df['DR_SDRG']!=0]))\n",
    "print(len(df[df['DR_ICDR']=='Normal']))\n",
    "print(len(df[df['DR_ICDR']!='Normal']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d2830ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (1478, 35)\n",
      "Test data shape: (634, 35)\n",
      "Getting validation set...\n",
      "Train data shape: (507, 35)\n",
      "Test data shape: (127, 35)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into train, test and validation:\n",
    "df_train, df_test = split_data(balanced_df, LABEL, TEST_SIZE, undersample=False)\n",
    "print('Getting validation set...')\n",
    "df_test, df_val = split_data(df_test, LABEL, 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0f9be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_classes(data, label_column):\n",
    "    # 클래스 별로 데이터를 그룹화\n",
    "    min_count = data[label_column].value_counts().min()\n",
    "    # 각 클래스에서 min_count만큼 샘플링\n",
    "    balanced_data = data.groupby(label_column).apply(lambda x: x.sample(min_count, random_state=42)).reset_index(drop=True)\n",
    "    \n",
    "    return balanced_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0bf0bd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>DR_ICDR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>img01208</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10823</th>\n",
       "      <td>img10824</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9371</th>\n",
       "      <td>img09372</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9397</th>\n",
       "      <td>img09398</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14584</th>\n",
       "      <td>img14585</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16242</th>\n",
       "      <td>img16243</td>\n",
       "      <td>Diabetic Retinopathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16243</th>\n",
       "      <td>img16244</td>\n",
       "      <td>Diabetic Retinopathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16244</th>\n",
       "      <td>img16245</td>\n",
       "      <td>Diabetic Retinopathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16260</th>\n",
       "      <td>img16261</td>\n",
       "      <td>Diabetic Retinopathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16261</th>\n",
       "      <td>img16262</td>\n",
       "      <td>Diabetic Retinopathy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2112 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id               DR_ICDR\n",
       "1207   img01208                Normal\n",
       "10823  img10824                Normal\n",
       "9371   img09372                Normal\n",
       "9397   img09398                Normal\n",
       "14584  img14585                Normal\n",
       "...         ...                   ...\n",
       "16242  img16243  Diabetic Retinopathy\n",
       "16243  img16244  Diabetic Retinopathy\n",
       "16244  img16245  Diabetic Retinopathy\n",
       "16260  img16261  Diabetic Retinopathy\n",
       "16261  img16262  Diabetic Retinopathy\n",
       "\n",
       "[2112 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df = balanced_df[['image_id', 'DR_ICDR']]\n",
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28bcfe15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled data (50%): 634\n",
      "Unlabeled data (50%): 1478\n",
      "Labeled data (25%): 422\n",
      "Unlabeled data (25%): 1690\n",
      "Train data shape: (1478, 2)\n",
      "Test data shape: (634, 2)\n",
      "Getting validation set...\n",
      "Train data shape: (507, 2)\n",
      "Test data shape: (127, 2)\n",
      "Train data shape: (443, 2)\n",
      "Test data shape: (191, 2)\n",
      "Getting validation set...\n",
      "Train data shape: (152, 2)\n",
      "Test data shape: (39, 2)\n",
      "Train data shape: (295, 2)\n",
      "Test data shape: (127, 2)\n",
      "Getting validation set...\n",
      "Train data shape: (101, 2)\n",
      "Test data shape: (26, 2)\n",
      "Train data shape: (148, 2)\n",
      "Test data shape: (64, 2)\n",
      "Getting validation set...\n",
      "Train data shape: (51, 2)\n",
      "Test data shape: (13, 2)\n"
     ]
    }
   ],
   "source": [
    "# 레이블된 데이터의 비율 설정\n",
    "label_ratio_50 = 0.3\n",
    "label_ratio_25 = 0.2\n",
    "label_ratio_12_5 = 0.1\n",
    "\n",
    "def get_data(frac):\n",
    "    normal_df = balanced_df[balanced_df['DR_ICDR']=='Normal']\n",
    "    DR_df = balanced_df[balanced_df['DR_ICDR']=='Diabetic Retinopathy']\n",
    "    DR_labeled_data = DR_df.sample(frac=frac, random_state=42)\n",
    "    normal_labeled_data = normal_df.sample(frac=frac, random_state=42)\n",
    "    labeled_data = pd.concat([DR_labeled_data, normal_labeled_data])\n",
    "    unlabeled_data = balanced_df.drop(labeled_data.index)\n",
    "    return labeled_data, unlabeled_data\n",
    "\n",
    "labeled_data_50, unlabeled_data_50 = get_data(label_ratio_50)\n",
    "labeled_data_25, unlabeled_data_25 = get_data(label_ratio_25)\n",
    "labeled_data_12_5, unlabeled_data_12_5 = get_data(label_ratio_12_5)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Labeled data (50%):\", len(labeled_data_50))\n",
    "print(\"Unlabeled data (50%):\", len(unlabeled_data_50))\n",
    "print(\"Labeled data (25%):\", len(labeled_data_25))\n",
    "print(\"Unlabeled data (25%):\", len(unlabeled_data_25))\n",
    "\n",
    "df_train, df_test = split_data(balanced_df, LABEL, TEST_SIZE, undersample=False)\n",
    "print('Getting validation set...')\n",
    "df_test, df_val = split_data(df_test, LABEL, 0.20)\n",
    "\n",
    "\n",
    "df_train50, df_test50 = split_data(labeled_data_50, LABEL, TEST_SIZE, undersample=False)\n",
    "print('Getting validation set...')\n",
    "df_test50, df_val50 = split_data(df_test50, LABEL, 0.20)\n",
    "\n",
    "df_train25, df_test25 = split_data(labeled_data_25, LABEL, TEST_SIZE, undersample=False)\n",
    "print('Getting validation set...')\n",
    "df_test25, df_val25 = split_data(df_test25, LABEL, 0.20)\n",
    "\n",
    "df_train12_5, df_test12_5 = split_data(labeled_data_12_5, LABEL, TEST_SIZE, undersample=False)\n",
    "print('Getting validation set...')\n",
    "df_test12_5, df_val12_5 = split_data(df_test12_5, LABEL, 0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e7975b",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "33f243f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the one hot encoder on the train set and get the labels for the test and validation sets:\n",
    "train_labels, mlb, train_columns = process_labels(df_train, col=LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa36756d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3137     Diabetic Retinopathy\n",
       "11595    Diabetic Retinopathy\n",
       "11891    Diabetic Retinopathy\n",
       "15465    Diabetic Retinopathy\n",
       "854      Diabetic Retinopathy\n",
       "                 ...         \n",
       "6969                   Normal\n",
       "6236                   Normal\n",
       "7172                   Normal\n",
       "5866                   Normal\n",
       "11402                  Normal\n",
       "Name: DR_ICDR, Length: 212, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data_12_5['DR_ICDR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fb38e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target image shape\n",
    "SHAPE = (224, 224)  # Adjust to your desired image size\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop(SHAPE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "    transforms.RandomRotation(50),  # Randomly rotate the image by up to 10 degrees\n",
    "])\n",
    "\n",
    "if NORM_MEAN is not None and NORM_STD is not None:\n",
    "    train_transforms.transforms.append(transforms.Normalize(mean=NORM_MEAN, std=NORM_STD))\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(SHAPE),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "if NORM_MEAN is not None and NORM_STD is not None:\n",
    "    test_transform.transforms.append(transforms.Normalize(mean=NORM_MEAN, std=NORM_STD))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5aa0b4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the custom dataset\n",
    "def get_dataset(df_labeled, df_unlabeled, df_test, df_val):\n",
    "    labeled_dataset = BRSETDataset(\n",
    "        df_labeled, \n",
    "        IMAGE_COL, \n",
    "        IMAGES, \n",
    "        LABEL, \n",
    "        mlb, \n",
    "        train_columns, \n",
    "        transform=train_transforms\n",
    "    )\n",
    "\n",
    "    unlabeled_dataset = BRSETDataset(\n",
    "        df_unlabeled, \n",
    "        IMAGE_COL, \n",
    "        IMAGES, \n",
    "        LABEL, \n",
    "        mlb, \n",
    "        train_columns, \n",
    "        transform=train_transforms  # You may need different transformations for unlabeled data\n",
    "    )\n",
    "\n",
    "    test_dataset = BRSETDataset(\n",
    "        df_test, \n",
    "        IMAGE_COL, \n",
    "        IMAGES, \n",
    "        LABEL, \n",
    "        mlb, \n",
    "        train_columns, \n",
    "        transform=test_transform\n",
    "    )\n",
    "\n",
    "    val_dataset = BRSETDataset(\n",
    "        df_val, \n",
    "        IMAGE_COL, \n",
    "        IMAGES, \n",
    "        LABEL, \n",
    "        mlb, \n",
    "        train_columns, \n",
    "        transform=test_transform\n",
    "    )\n",
    "    labeled_dataloader = DataLoader(labeled_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    unlabeled_dataloader = DataLoader(unlabeled_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    \n",
    "    return labeled_dataloader, unlabeled_dataloader, test_dataloader, val_dataloader\n",
    "\n",
    "\n",
    "\n",
    "train_dataloader, _, test_dataloader, val_dataloader = get_dataset(df_train, df_train, df_test, df_val)\n",
    "train_dataloader50, unlabeled_dataloader50, test_dataloader50, val_dataloader50 = get_dataset(df_train50, unlabeled_data_50, df_test50, df_val50)\n",
    "train_dataloader25, unlabeled_dataloader25, test_dataloader25, val_dataloader25 = get_dataset(df_train25, unlabeled_data_25, df_test25, df_val25)\n",
    "train_dataloader12_5, unlabeled_dataloader12_5, test_dataloader12_5, val_dataloader12_5 = get_dataset(df_train12_5, unlabeled_data_12_5, df_test12_5, df_val12_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "48801b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_not_loader(df_labeled, df_unlabeled, df_test, df_val):\n",
    "    labeled_dataset = BRSETDataset(\n",
    "        df_labeled, \n",
    "        IMAGE_COL, \n",
    "        IMAGES, \n",
    "        LABEL, \n",
    "        mlb, \n",
    "        train_columns, \n",
    "        transform=train_transforms\n",
    "    )\n",
    "\n",
    "    unlabeled_dataset = BRSETDataset(\n",
    "        df_unlabeled, \n",
    "        IMAGE_COL, \n",
    "        IMAGES, \n",
    "        LABEL, \n",
    "        mlb, \n",
    "        train_columns, \n",
    "        transform=train_transforms  # You may need different transformations for unlabeled data\n",
    "    )\n",
    "\n",
    "    test_dataset = BRSETDataset(\n",
    "        df_test, \n",
    "        IMAGE_COL, \n",
    "        IMAGES, \n",
    "        LABEL, \n",
    "        mlb, \n",
    "        train_columns, \n",
    "        transform=test_transform\n",
    "    )\n",
    "\n",
    "    val_dataset = BRSETDataset(\n",
    "        df_val, \n",
    "        IMAGE_COL, \n",
    "        IMAGES, \n",
    "        LABEL, \n",
    "        mlb, \n",
    "        train_columns, \n",
    "        transform=test_transform\n",
    "    )\n",
    "\n",
    "    return labeled_dataset, unlabeled_dataset, test_dataset, val_dataset\n",
    "\n",
    "train_dataset, _, test_dataset, val_dataset = get_dataset_not_loader(df_train, df_train, df_test, df_val)\n",
    "train_dataset50, unlabeled_dataset50, test_dataset50, val_dataset50 = get_dataset_not_loader(df_train50, unlabeled_data_50, df_test50, df_val50)\n",
    "train_dataset25, unlabeled_dataset25, test_dataset25, val_dataset25 = get_dataset_not_loader(df_train25, unlabeled_data_25, df_test25, df_val25)\n",
    "train_dataset12_5, unlabeled_dataset12_5, test_dataset12_5, val_dataset12_5 = get_dataset_not_loader(df_train12_5, unlabeled_data_12_5, df_test12_5, df_val12_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "edec00bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print 6 samples with their labels\n",
    "# # Iterate through the DataLoader and plot the images with labels\n",
    "# for batch in train_dataloader:\n",
    "#     images, labels = batch['image'], batch['labels']\n",
    "\n",
    "#     for i in range(len(images)):\n",
    "#         if i == 6:\n",
    "#             break\n",
    "#         plt.subplot(2, 3, i + 1)\n",
    "#         plt.imshow(images[i].permute(1, 2, 0))  # Permute to (H, W, C) from (C, H, W)\n",
    "#         plt.title(f\"Label: {labels[i]}\")\n",
    "#         plt.axis('off')\n",
    "#     plt.show()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038f0fb7",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a652c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "backbone_model = FoundationalCVModel(backbone=BACKBONE, mode=MODE)\n",
    "model = FoundationalCVModelWithClassifier(backbone_model, hidden=HIDDEN, num_classes=num_classes, mode=MODE, backbone_mode=backbone_mode)\n",
    "model.to(device)\n",
    "\n",
    "# Use DataParallel to parallelize the model across multiple GPUs\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model, [0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc7e0f3",
   "metadata": {},
   "source": [
    "### Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a49bc284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setting(train_dataloader):\n",
    "    if LOSS == 'focal_loss':\n",
    "        class_distribution = train_dataloader.dataset.labels.sum(axis=0)\n",
    "        print(f'Class distribution: {class_distribution}')\n",
    "        class_dis = np.array(class_distribution)\n",
    "        class_weights =1-class_dis/np.sum(class_dis)\n",
    "        weights = torch.tensor(class_weights).to(device)\n",
    "        #criterion = FocalLoss()  # Focal Loss\n",
    "        criterion = FocalLoss(gamma=2, alpha=weights)\n",
    "        class_indices = None\n",
    "    else:\n",
    "        class_distribution = None\n",
    "        class_dis = None\n",
    "        # Assuming train_loader.dataset.labels is a one-hot representation\n",
    "        class_indices = np.argmax(train_dataloader.dataset.labels, axis=1)\n",
    "        # Compute class weights using class indices\n",
    "        class_weights = compute_class_weight('balanced', classes=np.unique(class_indices), y=class_indices)\n",
    "        class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights).to(device)\n",
    "        weights = None\n",
    "        #criterion = nn.BCEWithLogitsLoss() # Binary Cross-Entropy Loss\n",
    "\n",
    "    if OPTIMIZER == 'adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    elif OPTIMIZER == 'adamw':\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    return class_distribution,class_dis,class_weights,weights,criterion,class_indices,optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e839a0e7",
   "metadata": {},
   "source": [
    "### Image quality assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c060ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_teacher(l_x, u_x, epochs):\n",
    "    # 모델 초기화\n",
    "    teacher = models.resnet50(pretrained=False,num_classes=2).cuda()\n",
    "    teacher\n",
    "    student = models.resnet50(pretrained=False,num_classes=2).cuda()\n",
    "\n",
    "    t_optimizer = optim.SGD(teacher.parameters(), lr=0.001, momentum=0.9)\n",
    "    s_optimizer = optim.SGD(student.parameters(), lr=0.001, momentum=0.9)\n",
    "    \n",
    "    for iteration in range(epochs):\n",
    "        teacher.train()\n",
    "        student.train()\n",
    "        t_optimizer.zero_grad()\n",
    "        s_optimizer.zero_grad()\n",
    "        for i in range(len(l_x)):\n",
    "            inputs = l_x.__getitem__(i)['image'].cuda()\n",
    "            inputs = inputs.unsqueeze(0).cuda()\n",
    "\n",
    "            labels = l_x.__getitem__(i)['labels'].cuda()\n",
    "            labels = labels.unsqueeze(0).cuda()  \n",
    "            t_l_logit = teacher(inputs)\n",
    "            t_l_loss = F.binary_cross_entropy_with_logits(t_l_logit, labels)\n",
    "\n",
    "            t_l_loss.backward()\n",
    "            t_optimizer.step()\n",
    "        \n",
    "        # 레이블이 없는 데이터에 대한 가상 레이블 생성 및 학습\n",
    "        for i in range(len(u_x)):\n",
    "            inputs = u_x.__getitem__(i)['image'].cuda()\n",
    "            inputs = inputs.unsqueeze(0).cuda()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                t_u_logit = teacher(inputs)\n",
    "                pseudo_y = torch.sigmoid(t_u_logit) \n",
    "            \n",
    "            s_u_logit = student(inputs)\n",
    "            s_u_loss = F.binary_cross_entropy_with_logits(s_u_logit, pseudo_y, reduction='mean')\n",
    "            s_u_loss.backward()\n",
    "            s_optimizer.step()\n",
    "\n",
    "        print('Epoch {}/{} completed'.format(iteration+1, 100))\n",
    "\n",
    "    return student\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5df7d45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_pseudo_label(l_x, u_x, epochs):    \n",
    "    teacher = models.resnet50(pretrained=False ,num_classes=2).cuda()\n",
    "    student = models.resnet50(pretrained=False, num_classes=2).cuda()\n",
    "    \n",
    "    t_optimizer = optim.SGD(teacher.parameters(), lr=0.001, momentum=0.9)\n",
    "    s_optimizer = optim.SGD(student.parameters(), lr=0.001, momentum=0.9)\n",
    "    \n",
    "    for iteration in range(epochs):\n",
    "        teacher.train()\n",
    "        student.train()\n",
    "        t_optimizer.zero_grad()\n",
    "        s_optimizer.zero_grad()        \n",
    "        for i in range(len(u_x)):\n",
    "            inputs = u_x.__getitem__(i)['image'].cuda()\n",
    "            inputs = inputs.unsqueeze(0).cuda()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                t_u_logit = teacher(inputs)\n",
    "                pseudo_y = torch.sigmoid(t_u_logit) \n",
    "            \n",
    "            s_u_logit = student(inputs)\n",
    "            s_u_loss = F.binary_cross_entropy_with_logits(s_u_logit, pseudo_y, reduction='none')\n",
    "            s_u_loss = s_u_loss[torch.abs(pseudo_y - 0.5) > 0.45].mean()\n",
    "            s_u_loss.backward()\n",
    "            s_optimizer.step()\n",
    "\n",
    "        for i in range(len(l_x)):\n",
    "            inputs = l_x.__getitem__(i)['image'].cuda()\n",
    "            inputs = inputs.unsqueeze(0).cuda()\n",
    "\n",
    "            labels = l_x.__getitem__(i)['labels'].cuda()\n",
    "            labels = labels.unsqueeze(0).cuda()  \n",
    "\n",
    "\n",
    "            s_l_logit_new = student(inputs)\n",
    "            s_l_loss_new = F.binary_cross_entropy_with_logits(s_l_logit_new, labels)\n",
    "            t_mpl_loss = s_l_loss_new\n",
    "\n",
    "            t_l_logit = teacher(inputs)\n",
    "            t_l_loss = F.binary_cross_entropy_with_logits(t_l_logit, labels)\n",
    "\n",
    "            (t_l_loss + t_mpl_loss).backward()\n",
    "            t_optimizer.step()\n",
    "            \n",
    "        print('Epoch {}/{} completed'.format(iteration+1, 100))\n",
    "\n",
    "    return student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fde67ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "def one_hot_encode(tensor, num_classes):\n",
    "    # 주어진 텐서의 크기를 확인하여 원-핫 인코딩된 텐서를 초기화합니다.\n",
    "    one_hot = torch.zeros(tensor.size(0), num_classes, device=tensor.device)\n",
    "    # 주어진 텐서의 값에 해당하는 인덱스를 1로 설정하여 원-핫 인코딩을 적용합니다.\n",
    "    one_hot.scatter_(1, tensor.unsqueeze(1), 1)\n",
    "    return one_hot\n",
    "\n",
    "# 모델의 예측을 생성하는 함수\n",
    "def predict(model, dataset):\n",
    "    predictions = []\n",
    "    num_classes = 2\n",
    "    model.eval()  # 모델을 평가 모드로 변경\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(dataset)):\n",
    "            inputs = dataset.__getitem__(i)['image'].cuda()\n",
    "            inputs = inputs.unsqueeze(0).cuda()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            predicted_class = torch.argmax(probabilities, dim=1)\n",
    "            \n",
    "            one_hot_encoded = one_hot_encode(predicted_class, num_classes)\n",
    "            one_hot_encoded.cpu()\n",
    "            predictions.append(one_hot_encoded.squeeze().cpu())\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# 정확도, F1 점수, 혼동 행렬을 계산하는 함수\n",
    "def evaluate(model, dataset, true_labels):\n",
    "    predictions = np.array(predict(model, dataset))\n",
    "\n",
    "    print(true_labels)\n",
    "    print(predictions)\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    return accuracy, f1, cm\n",
    "\n",
    "\n",
    "def evaluate_model(model, dataset):\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "    for example in dataset:\n",
    "        label = example['labels']\n",
    "        # 레이블이 배열이 아닌 경우에만 처리\n",
    "        if not isinstance(label, np.ndarray):\n",
    "            true_labels.append(label)\n",
    "\n",
    "            inputs = example['image'].cuda().unsqueeze(0)\n",
    "            outputs = model(inputs)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "            predictions.append(predicted_class)\n",
    "\n",
    "    # 실제 레이블과 예측된 레이블을 numpy 배열로 변환\n",
    "    true_labels = np.array(true_labels)\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    # 모델 평가\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "    # 결과 출력\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "\n",
    "\n",
    "# evaluate_model(mean_student_10, test_dataset12_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "79c24a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 1\n",
    "# mean_student_10 = mean_teacher(train_dataset12_5, unlabeled_dataset12_5, epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a75f9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m----> 2\u001b[0m meta_student_10 \u001b[39m=\u001b[39m meta_pseudo_label(train_dataset12_5, unlabeled_dataset12_5, epochs)\n\u001b[0;32m      3\u001b[0m mean_student_10 \u001b[39m=\u001b[39m mean_teacher(train_dataset12_5, unlabeled_dataset12_5, epochs)\n\u001b[0;32m      5\u001b[0m meta_student_20 \u001b[39m=\u001b[39m meta_pseudo_label(train_dataset25, unlabeled_dataset25, epochs)\n",
      "Cell \u001b[1;32mIn[18], line 14\u001b[0m, in \u001b[0;36mmeta_pseudo_label\u001b[1;34m(l_x, u_x, epochs)\u001b[0m\n\u001b[0;32m     12\u001b[0m s_optimizer\u001b[39m.\u001b[39mzero_grad()        \n\u001b[0;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(u_x)):\n\u001b[1;32m---> 14\u001b[0m     inputs \u001b[39m=\u001b[39m u_x\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(i)[\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m     15\u001b[0m     inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m     17\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\Desktop\\BRSET\\src\\data_loader.py:290\u001b[0m, in \u001b[0;36mBRSETDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    287\u001b[0m img_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_data[idx]\n\u001b[0;32m    289\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen( os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimages_dir, img_path \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.jpg\u001b[39m\u001b[39m'\u001b[39m) )\u001b[39m.\u001b[39mconvert(\u001b[39m\"\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 290\u001b[0m img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[0;32m    292\u001b[0m \u001b[39mreturn\u001b[39;00m {\n\u001b[0;32m    293\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m: torch\u001b[39m.\u001b[39mFloatTensor(img),\n\u001b[0;32m    294\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m: torch\u001b[39m.\u001b[39mFloatTensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels[idx])\n\u001b[0;32m    295\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:1379\u001b[0m, in \u001b[0;36mRandomRotation.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m   1376\u001b[0m         fill \u001b[39m=\u001b[39m [\u001b[39mfloat\u001b[39m(f) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m fill]\n\u001b[0;32m   1377\u001b[0m angle \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdegrees)\n\u001b[1;32m-> 1379\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mrotate(img, angle, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterpolation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexpand, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcenter, fill)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\functional.py:1140\u001b[0m, in \u001b[0;36mrotate\u001b[1;34m(img, angle, interpolation, expand, center, fill)\u001b[0m\n\u001b[0;32m   1137\u001b[0m \u001b[39m# due to current incoherence of rotation angle direction between affine and rotate implementations\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m \u001b[39m# we need to set -angle.\u001b[39;00m\n\u001b[0;32m   1139\u001b[0m matrix \u001b[39m=\u001b[39m _get_inverse_affine_matrix(center_f, \u001b[39m-\u001b[39mangle, [\u001b[39m0.0\u001b[39m, \u001b[39m0.0\u001b[39m], \u001b[39m1.0\u001b[39m, [\u001b[39m0.0\u001b[39m, \u001b[39m0.0\u001b[39m])\n\u001b[1;32m-> 1140\u001b[0m \u001b[39mreturn\u001b[39;00m F_t\u001b[39m.\u001b[39;49mrotate(img, matrix\u001b[39m=\u001b[39;49mmatrix, interpolation\u001b[39m=\u001b[39;49minterpolation\u001b[39m.\u001b[39;49mvalue, expand\u001b[39m=\u001b[39;49mexpand, fill\u001b[39m=\u001b[39;49mfill)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:669\u001b[0m, in \u001b[0;36mrotate\u001b[1;34m(img, matrix, interpolation, expand, fill)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[39m# grid will be generated on the same device as theta and img\u001b[39;00m\n\u001b[0;32m    667\u001b[0m grid \u001b[39m=\u001b[39m _gen_affine_grid(theta, w\u001b[39m=\u001b[39mw, h\u001b[39m=\u001b[39mh, ow\u001b[39m=\u001b[39mow, oh\u001b[39m=\u001b[39moh)\n\u001b[1;32m--> 669\u001b[0m \u001b[39mreturn\u001b[39;00m _apply_grid_transform(img, grid, interpolation, fill\u001b[39m=\u001b[39;49mfill)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:560\u001b[0m, in \u001b[0;36m_apply_grid_transform\u001b[1;34m(img, grid, mode, fill)\u001b[0m\n\u001b[0;32m    557\u001b[0m     mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones((img\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m1\u001b[39m, img\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m], img\u001b[39m.\u001b[39mshape[\u001b[39m3\u001b[39m]), dtype\u001b[39m=\u001b[39mimg\u001b[39m.\u001b[39mdtype, device\u001b[39m=\u001b[39mimg\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    558\u001b[0m     img \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((img, mask), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m--> 560\u001b[0m img \u001b[39m=\u001b[39m grid_sample(img, grid, mode\u001b[39m=\u001b[39;49mmode, padding_mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mzeros\u001b[39;49m\u001b[39m\"\u001b[39;49m, align_corners\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    562\u001b[0m \u001b[39m# Fill with required color\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39mif\u001b[39;00m fill \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:4244\u001b[0m, in \u001b[0;36mgrid_sample\u001b[1;34m(input, grid, mode, padding_mode, align_corners)\u001b[0m\n\u001b[0;32m   4236\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   4237\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mDefault grid_sample and affine_grid behavior has changed \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4238\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mto align_corners=False since 1.3.0. Please specify \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4239\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39malign_corners=True if the old behavior is desired. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4240\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSee the documentation of grid_sample for details.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4241\u001b[0m     )\n\u001b[0;32m   4242\u001b[0m     align_corners \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 4244\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mgrid_sampler(\u001b[39minput\u001b[39;49m, grid, mode_enum, padding_mode_enum, align_corners)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "meta_student_10 = meta_pseudo_label(train_dataset12_5, unlabeled_dataset12_5, epochs)\n",
    "mean_student_10 = mean_teacher(train_dataset12_5, unlabeled_dataset12_5, epochs)\n",
    "\n",
    "meta_student_20 = meta_pseudo_label(train_dataset25, unlabeled_dataset25, epochs)\n",
    "mean_student_20 = mean_teacher(train_dataset25, unlabeled_dataset25, epochs)\n",
    "\n",
    "meta_student_30 = meta_pseudo_label(train_dataset50, unlabeled_dataset50, epochs)\n",
    "mean_student_30 = mean_teacher(train_dataset50, unlabeled_dataset50, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5e73eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_student_pred_10 = evaluate_model(meta_student_10, test_dataset12_5)\n",
    "mean_student_pred_10 = evaluate_model(mean_student_10, test_dataset12_5)\n",
    "\n",
    "meta_student_pred_20 = evaluate_model(meta_student_20, test_dataset25)\n",
    "mean_student_pred_20 = evaluate_model(mean_student_20, test_dataset25)\n",
    "\n",
    "meta_student_pred_30 = evaluate_model(meta_student_30, test_dataset50)\n",
    "mean_student_pred_30 = evaluate_model(mean_student_30, test_dataset50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc878e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 completed\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 2 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[139], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m mean_student_10 \u001b[39m=\u001b[39m mean_teacher(train_dataset12_5, unlabeled_dataset12_5, epochs)\n\u001b[1;32m----> 2\u001b[0m mean_student_pred_10 \u001b[39m=\u001b[39m evaluate_model(mean_student_10, test_dataset12_5)\n",
      "Cell \u001b[1;32mIn[137], line 31\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, dataset)\u001b[0m\n\u001b[0;32m     28\u001b[0m true_labels \u001b[39m=\u001b[39m [example[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m example \u001b[39min\u001b[39;00m dataset]\n\u001b[0;32m     30\u001b[0m \u001b[39m# 모델 평가\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m accuracy, f1, confusion_matrix \u001b[39m=\u001b[39m evaluate(model, dataset, true_labels)\n\u001b[0;32m     33\u001b[0m \u001b[39m# 결과 출력\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy:\u001b[39m\u001b[39m\"\u001b[39m, accuracy)\n",
      "Cell \u001b[1;32mIn[137], line 19\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(model, dataset, true_labels)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(model, dataset, true_labels):\n\u001b[1;32m---> 19\u001b[0m     predictions \u001b[39m=\u001b[39m predict(model, dataset)\n\u001b[0;32m     20\u001b[0m     accuracy \u001b[39m=\u001b[39m accuracy_score(true_labels, predictions)\n\u001b[0;32m     21\u001b[0m     f1 \u001b[39m=\u001b[39m f1_score(true_labels, predictions)\n",
      "Cell \u001b[1;32mIn[137], line 13\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(model, dataset)\u001b[0m\n\u001b[0;32m     10\u001b[0m         inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m     12\u001b[0m         outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m---> 13\u001b[0m         predictions\u001b[39m.\u001b[39mappend(outputs\u001b[39m.\u001b[39;49mitem())  \u001b[39m# 예측 결과를 리스트에 추가 (예시로 첫 번째 출력값만 사용)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39mreturn\u001b[39;00m predictions\n",
      "\u001b[1;31mRuntimeError\u001b[0m: a Tensor with 2 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f899aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of unknown and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[151], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mean_student_pred_10 \u001b[39m=\u001b[39m evaluate_model(mean_student_10, test_dataset12_5)\n",
      "Cell \u001b[1;32mIn[150], line 34\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, dataset)\u001b[0m\n\u001b[0;32m     31\u001b[0m true_labels \u001b[39m=\u001b[39m [example[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m example \u001b[39min\u001b[39;00m dataset]\n\u001b[0;32m     33\u001b[0m \u001b[39m# 모델 평가\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m accuracy, f1, confusion_matrix \u001b[39m=\u001b[39m evaluate(model, dataset, true_labels)\n\u001b[0;32m     36\u001b[0m \u001b[39m# 결과 출력\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy:\u001b[39m\u001b[39m\"\u001b[39m, accuracy)\n",
      "Cell \u001b[1;32mIn[150], line 23\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(model, dataset, true_labels)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(model, dataset, true_labels):\n\u001b[0;32m     22\u001b[0m     predictions \u001b[39m=\u001b[39m predict(model, dataset)\n\u001b[1;32m---> 23\u001b[0m     accuracy \u001b[39m=\u001b[39m accuracy_score(true_labels, predictions)\n\u001b[0;32m     24\u001b[0m     f1 \u001b[39m=\u001b[39m f1_score(true_labels, predictions)\n\u001b[0;32m     25\u001b[0m     cm \u001b[39m=\u001b[39m confusion_matrix(true_labels, predictions)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    215\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:220\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \n\u001b[0;32m    156\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    221\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    222\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of unknown and binary targets"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6385a84d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
